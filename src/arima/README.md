# ARIMA Modeling for Prometheus Metrics

This folder contains a complete implementation of time series forecasting using ARIMA models with Prometheus metrics data.

## Overview

The ARIMA (AutoRegressive Integrated Moving Average) simulation demonstrates how to:

1. Transform raw Prometheus metrics data into a format suitable for time series modeling
2. Process and clean metrics data for both CPU and memory usage
3. Build ARIMA models to forecast future resource consumption
4. Evaluate model performance and visualize predictions

## Files in this Directory

- `data_transformer.py` - Handles converting Prometheus JSON data to pandas DataFrames
- `arima_model.py` - Implements the ARIMA modeling functionality
- `simulator.py` - End-to-end simulation script that ties everything together
- `traffic_maker.py` - Generates synthetic traffic, CPU, and memory spike data
- `run_arima_forecast.py` - Script to run ARIMA forecasting on specific metrics

## End-to-End Workflow

### Step 1: Generate Synthetic Data

Run the traffic maker to generate synthetic data that simulates traffic, CPU, and memory usage spikes for your Kubernetes services:

```bash
python traffic_maker.py
```

This will create synthetic metrics data in the `examples/prometheus` directory for:
- HTTP request rates for services (`gw-nginx`, `s0`, `s1`, `s2`)
- CPU usage for corresponding pods
- Memory usage for corresponding pods

The script also generates visualization plots showing the generated time series data.

### Step 2: Run ARIMA Analysis

You have multiple options to analyze the data with ARIMA forecasting:

#### Option 1: Run Analysis on a Specific Metric

```bash
python run_arima_forecast.py
```

By default, this runs ARIMA forecasting on the traffic data. You can specify different options:

```bash
# Analyze CPU usage data instead of traffic
python run_arima_forecast.py --metric cpu

# Analyze memory usage data
python run_arima_forecast.py --metric memory

# Specify a different service/pod to analyze
python run_arima_forecast.py --service s1

# Set a custom forecast horizon (number of steps)
python run_arima_forecast.py --forecast-steps 15
```

#### Option 2: Run Complete Simulation

For a comprehensive end-to-end test including anomaly detection:

```bash
python simulator.py
```

This runs the complete simulation pipeline:
1. Loads the data generated by `traffic_maker.py`
2. Transforms the data into a format suitable for ARIMA modeling
3. Trains ARIMA models for both CPU and memory usage
4. Generates forecasts and visualizes results
5. Simulates anomaly detection by comparing forecast vs. actual values

To run with specific options:

```bash
# Run simulation with anomaly testing enabled
python simulator.py --anomaly-test

# Set custom anomaly detection threshold
python simulator.py --threshold 2.5

# Analyze a specific service
python simulator.py --service s0
```

## Data Structure

### Input Data Structure

The input to the ARIMA model is the raw Prometheus response data, which looks like:

```json
{
  "data": {
    "result": [
      {
        "metric": {
          "pod": "s0-55bb4b4958-scd6b"
        },
        "values": [
          [1746246538.812, "0.004197698408680669"],
          [1746246598.812, "0.005706754195021715"],
          ...
        ]
      },
      ...
    ],
    "resultType": "matrix"
  },
  "status": "success"
}
```

### Intermediate Data Structure

This gets transformed into a pandas DataFrame with:
- Timestamp index (converted from Unix timestamp)
- One column per pod
- Values converted to appropriate units (percentage for CPU, MB for memory)

For CPU usage:
```
                        s0-55bb4b4958-scd6b  s1-84499d876f-bdfhj
2025-05-04 15:22:18.812             0.419770             0.399195
2025-05-04 15:23:18.812             0.570675             0.549569
2025-05-04 15:24:18.812             0.752086             0.674975
2025-05-04 15:25:18.812             0.864602             0.800377
```

For Memory usage:
```
                        s0-55bb4b4958-scd6b  s1-84499d876f-bdfhj
2025-05-04 15:22:14.753            133.402624           132.202496
2025-05-04 15:23:14.753            138.964992           138.829824
2025-05-04 15:24:14.753            142.176256           144.330752
2025-05-04 15:25:14.753            142.258176           144.355328
```

### ARIMA Input Structure

The final input to the ARIMA model is a pandas Series with:
- Regular timestamp index
- No missing values
- Appropriate units (% of core for CPU, MB for memory)
- Resampled to regular intervals

## Requirements

- numpy
- pandas
- matplotlib
- statsmodels
- scikit-learn

You can install the required packages with:

```bash
pip install -r requirements.txt
```

## Customizing the Simulation

You can modify parameters in the scripts:

### In `traffic_maker.py`:
- Change service names and pod names
- Adjust spike factors for traffic, CPU, and memory
- Modify the duration and interval of generated data

### In `run_arima_forecast.py`:
- Change the forecast horizon
- Modify the train/test split ratio
- Customize the visualization settings

### In `simulator.py`:
- Adjust anomaly detection thresholds
- Change the pods to analyze
- Customize the evaluation metrics